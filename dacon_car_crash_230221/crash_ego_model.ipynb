{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afef859a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.278845Z",
     "start_time": "2023-03-07T08:54:19.023624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/new_envs/gs/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f920b15",
   "metadata": {},
   "source": [
    "# crash-ego model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9cbb9",
   "metadata": {},
   "source": [
    "### 모델, 학습 함수 정의 및 config 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b24e58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.311150Z",
     "start_time": "2023-03-07T08:54:23.287111Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, video_path_list, label_list, aug_list):\n",
    "        self.video_path_list = video_path_list\n",
    "        self.label_list = label_list\n",
    "        self.aug_list = aug_list\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        frames = self.get_video(\n",
    "            self.video_path_list[index], \n",
    "            self.aug_list[index]\n",
    "            )\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return frames, label\n",
    "        else:\n",
    "            return frames\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_path_list)\n",
    "    \n",
    "    \n",
    "    def get_video(self, path, aug):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        \n",
    "        if (aug == 'N'):\n",
    "            for _ in range(CFG['VIDEO_LENGTH']):\n",
    "                _, img = cap.read()\n",
    "                img = cv2.resize(img, (CFG['HEIGHT'], CFG['WIDTH']))\n",
    "                img = img / 255.\n",
    "                frames.append(img)\n",
    "                \n",
    "        elif (aug == 'Y'):\n",
    "            for _ in range(CFG['VIDEO_LENGTH']):\n",
    "                _, img = cap.read()\n",
    "                frames.append(img)\n",
    "            frames = aug_video(frames)\n",
    "                \n",
    "        return torch.FloatTensor(np.array(frames)).permute(3, 0, 1, 2)\n",
    "    \n",
    "    \n",
    "def aug_video(vid):\n",
    "    seed = random.randint(0,99999)\n",
    "    aug_vid = []\n",
    "    for x in vid:\n",
    "        random.seed(seed)\n",
    "        tfms = gen_tfms()\n",
    "        aug_vid.append((tfms(image = np.asarray(x)))['image'])\n",
    "    return torch.from_numpy(np.stack(aug_vid))\n",
    "\n",
    "\n",
    "def gen_tfms():\n",
    "    seed = random.randint(0,99999)\n",
    "    random.seed(seed)\n",
    "    v = round(random.random(),2)\n",
    "    h = round(random.random(),2)\n",
    "    tfms = A.Compose([\n",
    "                A.Resize(width=CFG['HEIGHT'], height=CFG['WIDTH']),\n",
    "                A.VerticalFlip(p=v),\n",
    "                A.HorizontalFlip(p=h),\n",
    "                A.Normalize()\n",
    "                ], p=1) \n",
    "    return tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb924490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.323730Z",
     "start_time": "2023-03-07T08:54:23.314666Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.feature_extract = nn.Sequential(\n",
    "            ## input :  3 * 50 * frame 높이 * frame 너비 = channel * frames * img_size * img_size\n",
    "            nn.Conv3d(3, 8, (1, 3, 3)), # in_channels, out_channels, kernersize (default = stride1, padding0)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(8, 32, (1, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, (1, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(64, 128, (1, 2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.MaxPool3d((3, 7, 7)),\n",
    "        )\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.feature_extract(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e482e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.367052Z",
     "start_time": "2023-03-07T08:54:23.328127Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import _triple\n",
    "\n",
    "\n",
    "class SpatioTemporalConv(nn.Module):\n",
    "    r\"\"\"Applies a factored 3D convolution over an input signal composed of several input\n",
    "    planes with distinct spatial and time axes, by performing a 2D convolution over the\n",
    "    spatial axes to an intermediate subspace, followed by a 1D convolution over the time\n",
    "    axis to produce the final output.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input tensor\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int or tuple, optional): Zero-padding added to the sides of the input during their respective convolutions. Default: 0\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=False):\n",
    "        super(SpatioTemporalConv, self).__init__()\n",
    "\n",
    "        # if ints are entered, convert them to iterables, 1 -> [1, 1, 1]\n",
    "        kernel_size = _triple(kernel_size)\n",
    "        stride = _triple(stride)\n",
    "        padding = _triple(padding)\n",
    "\n",
    "\n",
    "        self.temporal_spatial_conv = nn.Conv3d(in_channels, out_channels, kernel_size,\n",
    "                                    stride=stride, padding=padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.temporal_spatial_conv(x))\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatioTemporalResBlock(nn.Module):\n",
    "    r\"\"\"Single block for the ResNet network. Uses SpatioTemporalConv in\n",
    "        the standard ResNet block layout (conv->batchnorm->ReLU->conv->batchnorm->sum->ReLU)\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input tensor.\n",
    "            out_channels (int): Number of channels in the output produced by the block.\n",
    "            kernel_size (int or tuple): Size of the convolving kernels.\n",
    "            downsample (bool, optional): If ``True``, the output size is to be smaller than the input. Default: ``False``\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, downsample=False):\n",
    "        super(SpatioTemporalResBlock, self).__init__()\n",
    "\n",
    "        # If downsample == True, the first conv of the layer has stride = 2\n",
    "        # to halve the residual output size, and the input x is passed\n",
    "        # through a seperate 1x1x1 conv with stride = 2 to also halve it.\n",
    "\n",
    "        # no pooling layers are used inside ResNet\n",
    "        self.downsample = downsample\n",
    "\n",
    "        # to allow for SAME padding\n",
    "        padding = kernel_size // 2\n",
    "\n",
    "        if self.downsample:\n",
    "            # downsample with stride =2 the input x\n",
    "            self.downsampleconv = SpatioTemporalConv(in_channels, out_channels, 1, stride=2)\n",
    "            self.downsamplebn = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "            # downsample with stride = 2when producing the residual\n",
    "            self.conv1 = SpatioTemporalConv(in_channels, out_channels, kernel_size, padding=padding, stride=2)\n",
    "        else:\n",
    "            self.conv1 = SpatioTemporalConv(in_channels, out_channels, kernel_size, padding=padding)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # standard conv->batchnorm->ReLU\n",
    "        self.conv2 = SpatioTemporalConv(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.outrelu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.relu1(self.bn1(self.conv1(x)))\n",
    "        res = self.bn2(self.conv2(res))\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.downsamplebn(self.downsampleconv(x))\n",
    "\n",
    "        return self.outrelu(x + res)\n",
    "\n",
    "\n",
    "class SpatioTemporalResLayer(nn.Module):\n",
    "    r\"\"\"Forms a single layer of the ResNet network, with a number of repeating\n",
    "    blocks of same output size stacked on top of each other\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input tensor.\n",
    "            out_channels (int): Number of channels in the output produced by the layer.\n",
    "            kernel_size (int or tuple): Size of the convolving kernels.\n",
    "            layer_size (int): Number of blocks to be stacked to form the layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layer. Default: SpatioTemporalResBlock.\n",
    "            downsample (bool, optional): If ``True``, the first block in layer will implement downsampling. Default: ``False``\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, layer_size, block_type=SpatioTemporalResBlock,\n",
    "                 downsample=False):\n",
    "\n",
    "        super(SpatioTemporalResLayer, self).__init__()\n",
    "\n",
    "        # implement the first block\n",
    "        self.block1 = block_type(in_channels, out_channels, kernel_size, downsample)\n",
    "\n",
    "        # prepare module list to hold all (layer_size - 1) blocks\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i in range(layer_size - 1):\n",
    "            # all these blocks are identical, and have downsample = False by default\n",
    "            self.blocks += [block_type(out_channels, out_channels, kernel_size)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class R3DNet(nn.Module):\n",
    "    r\"\"\"Forms the overall ResNet feature extractor by initializng 5 layers, with the number of blocks in\n",
    "    each layer set by layer_sizes, and by performing a global average pool at the end producing a\n",
    "    512-dimensional vector for each element in the batch.\n",
    "\n",
    "        Args:\n",
    "            layer_sizes (tuple): An iterable containing the number of blocks in each layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layers. Default: SpatioTemporalResBlock.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, block_type=SpatioTemporalResBlock):\n",
    "        super(R3DNet, self).__init__()\n",
    "\n",
    "        # first conv, with stride 1x2x2 and kernel size 3x7x7\n",
    "        self.conv1 = SpatioTemporalConv(3, 64, [3, 7, 7], stride=[1, 2, 2], padding=[1, 3, 3])\n",
    "        # output of conv2 is same size as of conv1, no downsampling needed. kernel_size 3x3x3\n",
    "        self.conv2 = SpatioTemporalResLayer(64, 64, 3, layer_sizes[0], block_type=block_type)\n",
    "        # each of the final three layers doubles num_channels, while performing downsampling\n",
    "        # inside the first block\n",
    "        self.conv3 = SpatioTemporalResLayer(64, 128, 3, layer_sizes[1], block_type=block_type, downsample=True)\n",
    "        self.conv4 = SpatioTemporalResLayer(128, 256, 3, layer_sizes[2], block_type=block_type, downsample=True)\n",
    "        self.conv5 = SpatioTemporalResLayer(256, 512, 3, layer_sizes[3], block_type=block_type, downsample=True)\n",
    "\n",
    "        # global average pooling of the output\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "\n",
    "        return x.view(-1, 512)\n",
    "\n",
    "\n",
    "class R3DClassifier(nn.Module):\n",
    "    r\"\"\"Forms a complete ResNet classifier producing vectors of size num_classes, by initializng 5 layers,\n",
    "    with the number of blocks in each layer set by layer_sizes, and by performing a global average pool\n",
    "    at the end producing a 512-dimensional vector for each element in the batch,\n",
    "    and passing them through a Linear layer.\n",
    "\n",
    "        Args:\n",
    "            num_classes(int): Number of classes in the data\n",
    "            layer_sizes (tuple): An iterable containing the number of blocks in each layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layers. Default: SpatioTemporalResBlock.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, layer_sizes, block_type=SpatioTemporalResBlock, pretrained=False):\n",
    "        super(R3DClassifier, self).__init__()\n",
    "\n",
    "        self.res3d = R3DNet(layer_sizes, block_type)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "        if pretrained:\n",
    "            self.__load_pretrained_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res3d(x)\n",
    "        logits = self.linear(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def __load_pretrained_weights(self):\n",
    "        s_dict = self.state_dict()\n",
    "        for name in s_dict:\n",
    "            print(name)\n",
    "            print(s_dict[name].size())\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def get_1x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the conv layer of the net.\n",
    "    \"\"\"\n",
    "    b = [model.res3d]\n",
    "    for i in range(len(b)):\n",
    "        for k in b[i].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k\n",
    "\n",
    "\n",
    "def get_10x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the fc layer of the net.\n",
    "    \"\"\"\n",
    "    b = [model.linear]\n",
    "    for j in range(len(b)):\n",
    "        for k in b[j].parameters():\n",
    "            if k.requires_grad:\n",
    "                yield k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752caff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a154f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.388198Z",
     "start_time": "2023-03-07T08:54:23.375199Z"
    }
   },
   "outputs": [],
   "source": [
    "## 모델 저장하는 부분 추가\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for videos, labels in tqdm(iter(train_loader)):\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(videos)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 : [{_val_score:.5f}]')\n",
    "        \n",
    "        torch.save(model.state_dict(), './ckp/car_crash_r3d_{0:02d}.ckpt'.format(epoch))\n",
    "        print(f'======== model saved - epoch : ', epoch)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42fa03f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.420422Z",
     "start_time": "2023-03-07T08:54:23.398549Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, trues = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for videos, labels in tqdm(iter(val_loader)):\n",
    "            videos = videos.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logit = model(videos)\n",
    "            \n",
    "            loss = criterion(logit, labels)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "            trues += labels.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "    \n",
    "    _val_score = f1_score(trues, preds, average='macro')\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1846d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025e2169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:23.441666Z",
     "start_time": "2023-03-07T08:54:23.429290Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'VIDEO_LENGTH':50, # 10프레임 * 5초\n",
    "    'HEIGHT':128,\n",
    "    'WIDTH':128,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':2,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ab60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8223bc9c",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5b4eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:25.084434Z",
     "start_time": "2023-03-07T08:54:25.010872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>crash_ego</th>\n",
       "      <th>aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./data/train/TRAIN_0000.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./data/train/TRAIN_0001.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./data/train/TRAIN_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./data/train/TRAIN_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./data/train/TRAIN_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>TRAIN_aug7943</td>\n",
       "      <td>./data/train/TRAIN_2685.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>TRAIN_aug7944</td>\n",
       "      <td>./data/train/TRAIN_2685.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>TRAIN_aug7952</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>TRAIN_aug7953</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>TRAIN_aug7954</td>\n",
       "      <td>./data/train/TRAIN_2692.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sample_id                   video_path  crash_ego aug\n",
       "0        TRAIN_0000  ./data/train/TRAIN_0000.mp4          2   N\n",
       "1        TRAIN_0001  ./data/train/TRAIN_0001.mp4          2   N\n",
       "2        TRAIN_0002  ./data/train/TRAIN_0002.mp4          0   N\n",
       "3        TRAIN_0003  ./data/train/TRAIN_0003.mp4          0   N\n",
       "4        TRAIN_0004  ./data/train/TRAIN_0004.mp4          1   N\n",
       "...             ...                          ...        ...  ..\n",
       "5258  TRAIN_aug7943  ./data/train/TRAIN_2685.mp4          2   Y\n",
       "5259  TRAIN_aug7944  ./data/train/TRAIN_2685.mp4          2   Y\n",
       "5260  TRAIN_aug7952  ./data/train/TRAIN_2692.mp4          2   Y\n",
       "5261  TRAIN_aug7953  ./data/train/TRAIN_2692.mp4          2   Y\n",
       "5262  TRAIN_aug7954  ./data/train/TRAIN_2692.mp4          2   Y\n",
       "\n",
       "[5263 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train_crash_ego_aug.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c9a8de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:28.065042Z",
     "start_time": "2023-03-07T08:54:28.044486Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f2544c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:28.395309Z",
     "start_time": "2023-03-07T08:54:28.373939Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "train_df, val_df, _, _ = train_test_split(df, df['crash_ego'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6e3345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:28.654451Z",
     "start_time": "2023-03-07T08:54:28.643989Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    train_df['video_path'].values, \n",
    "    train_df['crash_ego'].values, \n",
    "    train_df['aug'].values, \n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = CFG['BATCH_SIZE'], \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    "    )\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    val_df['video_path'].values, \n",
    "    val_df['crash_ego'].values, \n",
    "    val_df['aug'].values,\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size = CFG['BATCH_SIZE'], \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086274e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T08:54:34.414078Z",
     "start_time": "2023-03-07T08:54:34.086467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.9490, 0.9608, 0.9843,  ..., 0.8078, 0.8078, 0.8667],\n",
       "           [0.9451, 0.9490, 0.9804,  ..., 0.7569, 0.7725, 0.8588],\n",
       "           [0.9451, 0.9490, 0.9804,  ..., 0.7020, 0.7765, 0.8588],\n",
       "           ...,\n",
       "           [0.3333, 0.3608, 0.3333,  ..., 0.1686, 0.1255, 0.1294],\n",
       "           [0.3647, 0.3373, 0.3490,  ..., 0.1765, 0.1529, 0.1333],\n",
       "           [0.3569, 0.3176, 0.3333,  ..., 0.1804, 0.1647, 0.1490]],\n",
       " \n",
       "          [[0.9490, 0.9725, 0.9843,  ..., 0.8039, 0.8078, 0.8667],\n",
       "           [0.9451, 0.9686, 0.9804,  ..., 0.7529, 0.7922, 0.8627],\n",
       "           [0.9451, 0.9608, 0.9804,  ..., 0.7059, 0.7765, 0.8588],\n",
       "           ...,\n",
       "           [0.3333, 0.3569, 0.3255,  ..., 0.1647, 0.1333, 0.1412],\n",
       "           [0.3647, 0.3451, 0.3529,  ..., 0.1882, 0.1765, 0.1647],\n",
       "           [0.3529, 0.3176, 0.3333,  ..., 0.1882, 0.1765, 0.1529]],\n",
       " \n",
       "          [[0.9490, 0.9804, 0.9843,  ..., 0.8196, 0.8078, 0.8667],\n",
       "           [0.9490, 0.9804, 0.9843,  ..., 0.7569, 0.7804, 0.8627],\n",
       "           [0.9451, 0.9765, 0.9843,  ..., 0.7098, 0.7765, 0.8588],\n",
       "           ...,\n",
       "           [0.3255, 0.3569, 0.3294,  ..., 0.1569, 0.1333, 0.1373],\n",
       "           [0.3725, 0.3451, 0.3569,  ..., 0.1882, 0.1725, 0.1529],\n",
       "           [0.3529, 0.3176, 0.3333,  ..., 0.1804, 0.1765, 0.1569]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.9647, 0.9725, 0.9843,  ..., 0.8157, 0.8000, 0.8667],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.7569, 0.7882, 0.8627],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.6980, 0.7608, 0.8588],\n",
       "           ...,\n",
       "           [0.3176, 0.3490, 0.3216,  ..., 0.1529, 0.1333, 0.1412],\n",
       "           [0.3647, 0.3373, 0.3569,  ..., 0.1765, 0.1686, 0.1451],\n",
       "           [0.3373, 0.3137, 0.3373,  ..., 0.1804, 0.1647, 0.1569]],\n",
       " \n",
       "          [[0.9647, 0.9725, 0.9843,  ..., 0.8078, 0.7961, 0.8627],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.7569, 0.7765, 0.8588],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.6902, 0.7569, 0.8588],\n",
       "           ...,\n",
       "           [0.3294, 0.3490, 0.3216,  ..., 0.1569, 0.1373, 0.1373],\n",
       "           [0.3804, 0.3373, 0.3490,  ..., 0.1804, 0.1765, 0.1451],\n",
       "           [0.3294, 0.3216, 0.3373,  ..., 0.1804, 0.1725, 0.1529]],\n",
       " \n",
       "          [[0.9647, 0.9725, 0.9843,  ..., 0.8078, 0.7961, 0.8627],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.7569, 0.7765, 0.8588],\n",
       "           [0.9647, 0.9725, 0.9843,  ..., 0.6902, 0.7569, 0.8588],\n",
       "           ...,\n",
       "           [0.3294, 0.3490, 0.3176,  ..., 0.1569, 0.1373, 0.1373],\n",
       "           [0.3804, 0.3373, 0.3490,  ..., 0.1804, 0.1765, 0.1451],\n",
       "           [0.3294, 0.3216, 0.3373,  ..., 0.1804, 0.1725, 0.1529]]],\n",
       " \n",
       " \n",
       "         [[[0.9804, 0.9922, 0.9882,  ..., 0.8196, 0.8196, 0.8784],\n",
       "           [0.9765, 0.9804, 0.9843,  ..., 0.7686, 0.7882, 0.8706],\n",
       "           [0.9765, 0.9804, 0.9843,  ..., 0.7137, 0.7882, 0.8706],\n",
       "           ...,\n",
       "           [0.3765, 0.4039, 0.3882,  ..., 0.2510, 0.2078, 0.2157],\n",
       "           [0.4078, 0.3804, 0.4039,  ..., 0.2588, 0.2392, 0.2196],\n",
       "           [0.4000, 0.3608, 0.3882,  ..., 0.2627, 0.2510, 0.2353]],\n",
       " \n",
       "          [[0.9804, 0.9882, 0.9882,  ..., 0.8157, 0.8196, 0.8784],\n",
       "           [0.9765, 0.9843, 0.9843,  ..., 0.7647, 0.8039, 0.8745],\n",
       "           [0.9765, 0.9765, 0.9843,  ..., 0.7176, 0.7882, 0.8706],\n",
       "           ...,\n",
       "           [0.3765, 0.3961, 0.3804,  ..., 0.2471, 0.2000, 0.2078],\n",
       "           [0.4078, 0.3882, 0.4078,  ..., 0.2706, 0.2431, 0.2314],\n",
       "           [0.3961, 0.3608, 0.3843,  ..., 0.2706, 0.2431, 0.2196]],\n",
       " \n",
       "          [[0.9804, 0.9843, 0.9882,  ..., 0.8196, 0.8196, 0.8784],\n",
       "           [0.9804, 0.9843, 0.9882,  ..., 0.7569, 0.7922, 0.8745],\n",
       "           [0.9765, 0.9804, 0.9882,  ..., 0.7098, 0.7882, 0.8706],\n",
       "           ...,\n",
       "           [0.3686, 0.3961, 0.3843,  ..., 0.2392, 0.2078, 0.2118],\n",
       "           [0.4157, 0.3882, 0.4118,  ..., 0.2706, 0.2353, 0.2196],\n",
       "           [0.3961, 0.3608, 0.3843,  ..., 0.2627, 0.2431, 0.2235]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.9804, 0.9882, 0.9882,  ..., 0.8235, 0.8078, 0.8784],\n",
       "           [0.9804, 0.9882, 0.9882,  ..., 0.7647, 0.8000, 0.8784],\n",
       "           [0.9804, 0.9882, 0.9882,  ..., 0.7059, 0.7686, 0.8706],\n",
       "           ...,\n",
       "           [0.3765, 0.4078, 0.3765,  ..., 0.2392, 0.2157, 0.2078],\n",
       "           [0.4235, 0.3961, 0.4118,  ..., 0.2627, 0.2471, 0.2118],\n",
       "           [0.3961, 0.3725, 0.3922,  ..., 0.2667, 0.2431, 0.2235]],\n",
       " \n",
       "          [[0.9882, 0.9882, 0.9882,  ..., 0.8196, 0.8078, 0.8745],\n",
       "           [0.9882, 0.9882, 0.9882,  ..., 0.7686, 0.7882, 0.8706],\n",
       "           [0.9882, 0.9882, 0.9882,  ..., 0.7020, 0.7686, 0.8706],\n",
       "           ...,\n",
       "           [0.3882, 0.4118, 0.3804,  ..., 0.2431, 0.2039, 0.2039],\n",
       "           [0.4392, 0.3961, 0.4078,  ..., 0.2667, 0.2431, 0.2118],\n",
       "           [0.3882, 0.3804, 0.3961,  ..., 0.2667, 0.2392, 0.2196]],\n",
       " \n",
       "          [[0.9882, 0.9882, 0.9882,  ..., 0.8196, 0.8078, 0.8745],\n",
       "           [0.9882, 0.9882, 0.9882,  ..., 0.7686, 0.7882, 0.8706],\n",
       "           [0.9882, 0.9882, 0.9882,  ..., 0.7020, 0.7686, 0.8706],\n",
       "           ...,\n",
       "           [0.3882, 0.4118, 0.3765,  ..., 0.2431, 0.2039, 0.2039],\n",
       "           [0.4392, 0.3961, 0.4078,  ..., 0.2667, 0.2431, 0.2118],\n",
       "           [0.3882, 0.3804, 0.3961,  ..., 0.2667, 0.2392, 0.2196]]],\n",
       " \n",
       " \n",
       "         [[[0.9137, 0.9255, 0.9451,  ..., 0.7294, 0.7294, 0.7882],\n",
       "           [0.9098, 0.9137, 0.9412,  ..., 0.6784, 0.6941, 0.7804],\n",
       "           [0.9098, 0.9137, 0.9412,  ..., 0.6235, 0.6980, 0.7804],\n",
       "           ...,\n",
       "           [0.3529, 0.3804, 0.3569,  ..., 0.2196, 0.1922, 0.1961],\n",
       "           [0.3843, 0.3569, 0.3725,  ..., 0.2275, 0.2196, 0.2000],\n",
       "           [0.3765, 0.3373, 0.3569,  ..., 0.2314, 0.2314, 0.2157]],\n",
       " \n",
       "          [[0.9137, 0.9333, 0.9451,  ..., 0.7255, 0.7294, 0.7882],\n",
       "           [0.9098, 0.9294, 0.9412,  ..., 0.6745, 0.7137, 0.7843],\n",
       "           [0.9098, 0.9216, 0.9412,  ..., 0.6275, 0.6980, 0.7804],\n",
       "           ...,\n",
       "           [0.3529, 0.3765, 0.3490,  ..., 0.2157, 0.1843, 0.1922],\n",
       "           [0.3843, 0.3647, 0.3765,  ..., 0.2392, 0.2275, 0.2157],\n",
       "           [0.3686, 0.3373, 0.3529,  ..., 0.2392, 0.2275, 0.2039]],\n",
       " \n",
       "          [[0.9137, 0.9412, 0.9451,  ..., 0.7333, 0.7294, 0.7882],\n",
       "           [0.9137, 0.9412, 0.9451,  ..., 0.6745, 0.7020, 0.7843],\n",
       "           [0.9098, 0.9373, 0.9451,  ..., 0.6235, 0.6980, 0.7804],\n",
       "           ...,\n",
       "           [0.3451, 0.3765, 0.3529,  ..., 0.2078, 0.1922, 0.1922],\n",
       "           [0.3922, 0.3647, 0.3804,  ..., 0.2392, 0.2196, 0.2039],\n",
       "           [0.3686, 0.3373, 0.3529,  ..., 0.2314, 0.2275, 0.2078]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.9255, 0.9333, 0.9451,  ..., 0.7412, 0.7255, 0.7882],\n",
       "           [0.9255, 0.9333, 0.9451,  ..., 0.6824, 0.7137, 0.7843],\n",
       "           [0.9255, 0.9333, 0.9373,  ..., 0.6235, 0.6863, 0.7804],\n",
       "           ...,\n",
       "           [0.3333, 0.3647, 0.3451,  ..., 0.2196, 0.1882, 0.1922],\n",
       "           [0.3804, 0.3529, 0.3804,  ..., 0.2431, 0.2275, 0.1961],\n",
       "           [0.3529, 0.3294, 0.3608,  ..., 0.2471, 0.2235, 0.2078]],\n",
       " \n",
       "          [[0.9137, 0.9412, 0.9451,  ..., 0.7294, 0.7176, 0.7843],\n",
       "           [0.9137, 0.9412, 0.9451,  ..., 0.6784, 0.6980, 0.7804],\n",
       "           [0.9137, 0.9412, 0.9451,  ..., 0.6118, 0.6784, 0.7804],\n",
       "           ...,\n",
       "           [0.3451, 0.3647, 0.3373,  ..., 0.2235, 0.1882, 0.1882],\n",
       "           [0.3961, 0.3529, 0.3647,  ..., 0.2471, 0.2275, 0.1961],\n",
       "           [0.3451, 0.3373, 0.3529,  ..., 0.2471, 0.2235, 0.2039]],\n",
       " \n",
       "          [[0.9137, 0.9333, 0.9451,  ..., 0.7294, 0.7176, 0.7843],\n",
       "           [0.9137, 0.9333, 0.9451,  ..., 0.6784, 0.6980, 0.7804],\n",
       "           [0.9137, 0.9333, 0.9451,  ..., 0.6118, 0.6784, 0.7804],\n",
       "           ...,\n",
       "           [0.3451, 0.3647, 0.3333,  ..., 0.2235, 0.1882, 0.1882],\n",
       "           [0.3961, 0.3529, 0.3647,  ..., 0.2471, 0.2275, 0.1961],\n",
       "           [0.3451, 0.3373, 0.3529,  ..., 0.2471, 0.2235, 0.2039]]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920d81d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T02:17:27.053851Z",
     "start_time": "2023-03-07T02:16:56.614465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30186696281846ab8b377b1947c2ea96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780c4a2b6040492eac3a828bdcf48a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.23224] Val Loss : [7.58030] Val F1 : [0.00000]\n",
      "======== model saved - epoch :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca77303080274b12898d4d095f033930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02640068affb45348f924c3a892f2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.77692] Val Loss : [8.73670] Val F1 : [0.00000]\n",
      "======== model saved - epoch :  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020adbebd0e0489cb97584003e48d832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddf6c3ecfa34c9184d8a6cff98c5f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.83853] Val Loss : [1.84765] Val F1 : [0.00000]\n",
      "======== model saved - epoch :  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946d215d0bdb4bfaabad3950e0192f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d518690313473d9fbbb07c53b32c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.62919] Val Loss : [0.24121] Val F1 : [1.00000]\n",
      "======== model saved - epoch :  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbd77cd6a1f4f7886dfc7ad3334333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76306adf7f68446e960d9e3fee200548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.22920] Val Loss : [1.53594] Val F1 : [0.00000]\n",
      "======== model saved - epoch :  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e2519746794f8a8797c8ddafcfaba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23c3fe70dac43158f84ec7a1b425baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.38328] Val Loss : [0.06271] Val F1 : [1.00000]\n",
      "======== model saved - epoch :  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f132dd722bc24336ae8b3990f700688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f080df5e1844fca245c0d926f12ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.11280] Val Loss : [0.00033] Val F1 : [1.00000]\n",
      "======== model saved - epoch :  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7451c2df03724c88ada3d789026c1e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3481924/981629194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0minfer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3481924/3439139496.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mvideos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/new_envs/gs/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/new_envs/gs/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/new_envs/gs/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/new_envs/gs/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3481924/1073085492.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         frames = self.get_video(\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_path_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maug_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3481924/1073085492.py\u001b[0m in \u001b[0;36mget_video\u001b[0;34m(self, path, aug)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maug\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VIDEO_LENGTH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HEIGHT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WIDTH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = BaseModel()\n",
    "model = R3DClassifier(num_classes=3, layer_sizes=(2, 2, 2, 2))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.5, \n",
    "    patience=2,\n",
    "    threshold_mode='abs',\n",
    "    min_lr=1e-8, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3da3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c5297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b46c6a73",
   "metadata": {},
   "source": [
    "### infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab449b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckp = torch.load('./ckp/baseline_01.ckpt')\n",
    "# model = R3DClassifier(num_classes=3, layer_sizes=(2, 2, 2, 2))\n",
    "# model.load_state_dict(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "for v in range(len(test['video_path'])):\n",
    "    temp = test.loc[v,'video_path'].split('./')[-1]\n",
    "    new_path = './data/' + temp\n",
    "    test.loc[v,'video_path'] = new_path\n",
    "test['aug'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ac219",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(\n",
    "    test['video_path'].values, \n",
    "    None, \n",
    "    test['aug']\n",
    "    )\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for videos in tqdm(iter(test_loader)):\n",
    "            videos = videos.to(device)\n",
    "            \n",
    "            logit = model(videos)\n",
    "\n",
    "            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd9066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "gs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
